{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a81bf60f-c1fd-4f9b-b249-11ffe7b8f239",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Following code loads the raw GDELT - GKG files available at \"http://data.gdeltproject.org/gkg/index.html\" and contructs a knowledge graph. Further, it performs link prediction to infer missing/potential links in the knowledge graph based on the CNGF link prediction algorithm described in this paper \"The Algorithm of Link Prediction on Social Network\" available at \"https://www.hindawi.com/journals/mpe/2013/125123/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2513b12c-0809-482c-8be3-56ce9fc9c660",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"EMT678-LinkPrediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a2a8544-12e0-4bf0-856d-00710410383b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Row\n",
    "from graphframes import *\n",
    "import re\n",
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa6e2565-186e-4b70-920b-43ad237f09e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gkg_1207 = spark.read.csv(\"/Volumes/temp_gkg_yolo/default/gkg_files/20231110.gkg.csv\",sep=\"\\t\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cdc061e-e65d-4574-bc4b-6d29f944edc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|    DATE|NUMARTS|COUNTS|              THEMES|           LOCATIONS|             PERSONS|       ORGANIZATIONS|                TONE|       CAMEOEVENTIDS|             SOURCES|          SOURCEURLS|\n+--------+-------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|20231110|      1|  NULL|TOURISM;WB_825_TO...|1#South Korea#KS#...|      aurojyoti bose|                NULL|-3.79746835443038...|1139481783,113948...|hotelnewsresource...|https://www.hotel...|\n|20231110|      2|  NULL|TAX_FNCACT;TAX_FN...|5#Suffolk, Suffol...|                NULL| stores in lowestoft|-2.83018867924528...|1139282290,113928...|edp24.co.uk;eadt....|https://www.edp24...|\n|20231110|      1|  NULL|TAX_FNCACT;TAX_FN...|1#France#FR#FR#46...|bea arthur;brad b...|marine corp women...|-2.84552845528455...|1139499186,113949...|      ocregister.com|https://www.ocreg...|\n|20231110|      1|  NULL|EPU_ECONOMY_HISTO...|2#New Jersey, Uni...|michael perry;jen...|clinical services...|6.53061224489796,...|                NULL|   streetinsider.com|https://www.stree...|\n|20231110|      1|  NULL|TAX_FNCACT;TAX_FN...|1#United States#U...|ricci lea castell...|office of inspect...|-4.66101694915254...|          1139279949| ravallirepublic.com|https://ravallire...|\n+--------+-------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gkg_1207.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7daa7dbd-1d7b-47a2-acfe-ee02f6bcf18c",
     "showTitle": true,
     "title": ""
    }
   },
   "source": [
    "Select the PERSONS, ORGANIZATIONS and THEMES columns from the master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4815069c-50e6-4a21-a230-f270ea24d482",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gkg_reduced = gkg_1207.select(\"THEMES\",\"PERSONS\",\"ORGANIZATIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33398208-62cd-4005-827d-4834e1ed1051",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Filtering the events to be based in India and contain ARMEDCONFLICT in the list of themes assigned to an event, an event can contain more than 1 theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd906308-089b-41e8-bfc4-8dfba4e54ffa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_armed_conflict = gkg_reduced.filter(F.col(\"THEMES\").like(\"%ARMEDCONFLICT%\") & F.col(\"LOCATIONS\").like(\"%India%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "006a5e6e-cea3-44ec-b732-921fcf996cbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The get_top_results function defined below returns a list of the entities in a column with their corresponding count of occurences sorted in descending order of the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1c818ee-b553-438e-9ae9-2d759047029f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "def get_top_results(df,column_name):\n",
    "    split_df = df.select(F.split(F.col(column_name),\";\").alias(\"split_list\")).select(F.explode(F.col(\"split_list\")).alias(\"final_list\"))\n",
    "    top_list = split_df.groupBy(\"final_list\").count().sort(F.desc(\"COUNT\"))\n",
    "    return top_list.select(\"final_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5bf89b8-cbcc-426c-97a3-56e5d2425c84",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The filter_dataframe function defined below filters the dataframe to return only rows containing the entities passed through the 'filter_list' argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddb8dfb3-a18b-4463-9d66-9f858010b420",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import or_\n",
    "def filter_dataframe(df,filter_list):\n",
    "    df = df.filter(reduce(or_, [df.PERSONS.rlike(s) for s in filter_list]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f176bac-1ec6-4141-946d-f165ffa092ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The above mentioned functions are used to only get rows containing the top n \"PERSONS\". It can be noted here that this does not mean our graph only contains these n vertices, rather it contains all the vertices that these top n persons are connected to as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7175b65a-f427-44eb-a1ab-31a0a010e83c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_persons = get_top_results(df_armed_conflict,\"PERSONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59d9bcc-7ab8-46cc-a00c-d698b70458d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list = top_persons.select('final_list').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed745e73-3957-4ddc-a0dd-d315411b7b3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_20_persons_df = filter_dataframe(df_armed_conflict, list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fafba44a-7dbf-4071-b467-7caa2781e017",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The get_vertices_edges() function, returns the list of vertices and edges that we will use to construct our knowledge graph.\n",
    "Steps:\n",
    "1. Merge PERSONS AND ORGANIZATIONS columns to form a string of all vertices to be extracted from a given row(event).\n",
    "2. Split the above formed string to get a list of all the vertices. This dataframe now contains a list of vertices and a list of THEMES that will connect each of these vertices.\n",
    "3. Form a df_vertices dataframe by exploding the list of vertices and assigning an id to each row(now containing 1 vertex per row).\n",
    "4. To generate each of our edges, I form a list of vertex-pairs from a given list of vertices by using a Python UDF\n",
    "5. I then explode this list of vertex-pairs and the list of THEMES for each vertex-pair, to get the final df_edges dataframe that contains (vertex1,vertex2,theme) columns as the (source_node,destination_node,relationship) that forms an edge in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ce075bf-ac01-438f-8675-8201f49e965a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_vertices_edges(df):\n",
    "    df = df.withColumn(\"merged\", F.concat_ws(\";\", df[\"ORGANIZATIONS\"], df[\"PERSONS\"]))\n",
    "    df_merged = df.select(\"merged\",\"THEMES\")\n",
    "    df_merged = df_merged.select(F.split(F.col(\"merged\"),\";\").alias(\"merged\"),\"THEMES\")\n",
    "    df_vertices = df_merged.select(F.explode(F.col(\"merged\"))).distinct()\n",
    "    df_vertices = df_vertices.withColumn(\"id\",F.monotonically_increasing_id())\n",
    "    df_combinations = df_merged.withColumn('merged',generate_pairs(df_merged['merged']))\n",
    "    df_combinations = df_combinations.select(F.explode(F.col(\"merged\")).alias(\"edges\"),\"THEMES\")\n",
    "    df_edges = df_combinations.select(\"edges\",F.explode(F.split(F.col(\"THEMES\"),\";\")))\n",
    "    return df_vertices,df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "562dc447-9f80-42e8-aad0-feb307f2376a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "I used the UDF generate_pairs defined below to generate a list of pairs given a list of strings. \n",
    "(eg) - ['Roger Federer','Lebron James','Michael Schumacher','Niki Lauda'] --> [['Roger Federer','Lebron James'],['Roger Federer','Lebron James'],['Roger Federer','Michael Schumacher'],['Roger Federer','Niki Lauda'],['Lebron James','Michael Schumacher'],['Lebron James','Niki Lauda'],['Michael Schumacher','Niki Lauda']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a90ec3b4-389a-4f19-9d74-97283b538d30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import itertools\n",
    "\n",
    "@udf(returnType=ArrayType(ArrayType(StringType())))\n",
    "def generate_pairs(x):\n",
    "    return [list(pair) for pair in itertools.combinations(x, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90768642-20e3-4f2a-ae01-f0ea5bb0a419",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vertices,df_edges = get_vertices_edges(top_20_persons_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c52ab59b-2cec-4e57-bf30-4136e440abe0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Renaming the columns in df_edges to be compatible with the graphframes api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "719444bf-a341-427b-9ead-34a90455b99f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_edges = df_edges.withColumn(\"src\",F.col(\"edges\")[0]).withColumn(\"dst\",F.col(\"edges\")[1]).withColumnRenamed(\"col\",\"relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11138470-105b-469b-bdf0-d6740427aee0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n|                 col| id|\n+--------------------+---+\n|association of so...|  0|\n|     ayman al-safadi|  1|\n|       amrit vatikas|  2|\n|bharatiya janata ...|  3|\n|    syed zafar islam|  4|\n|      krishna madiga|  5|\n|         white house|  6|\n|     charles q brown|  7|\n|azadi ka amrit ma...|  8|\n|indian defense mi...|  9|\n+--------------------+---+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_vertices.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00818db1-e8ae-4f8a-a9b2-8062dba82c36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_edges = df_edges.drop(\"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f7cbb02-891a-463e-b1f4-12576999f077",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-------------------------+-----------+\n|relationship                 |src                      |dst        |\n+-----------------------------+-------------------------+-----------+\n|TAX_FNCACT                   |palestinian prisoner club|arab league|\n|TAX_FNCACT_SECRETARY         |palestinian prisoner club|arab league|\n|TAX_FNCACT_SECRETARY_OF_STATE|palestinian prisoner club|arab league|\n|TAX_ETHNICITY                |palestinian prisoner club|arab league|\n|TAX_ETHNICITY_PALESTINIANS   |palestinian prisoner club|arab league|\n|KILL                         |palestinian prisoner club|arab league|\n|CRISISLEX_T03_DEAD           |palestinian prisoner club|arab league|\n|CRISISLEX_CRISISLEXREC       |palestinian prisoner club|arab league|\n|CRISISLEX_T02_INJURED        |palestinian prisoner club|arab league|\n|TAX_WORLDMAMMALS             |palestinian prisoner club|arab league|\n+-----------------------------+-------------------------+-----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_edges.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6c94a69-4da6-4503-9082-b5c091bc8286",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1311"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vertices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43af99ff-53dd-4fb6-b128-8ddcc4e8d214",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13274146\n"
     ]
    }
   ],
   "source": [
    "print(df_edges.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "278314b2-f26e-4d17-b85f-aea875f5aaa5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Importing the graphframes package and creating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5967ad89-2db1-42a3-b655-1639086e3b3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20616a72-5cb6-4c36-9514-ce648f1ce9f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "graph = GraphFrame(df_vertices, df_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e448388-06cc-48b4-896f-fe394e3f430d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The following is the implementation of the CNGF algorithm. It computes a similarity score between each vertex in the graph. These similarity scores can later be used to predict links between vertices based on a given threshold of similarty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ef4d9ce-b385-4b09-9d91-033c90241bbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_neighbours(vertex):\n",
    "    \"\"\"\n",
    "    Given a node of the graph, this function finds all it's neighbours. Since\n",
    "    it is designed for undirected graphs, the neighbours of the node are found\n",
    "    in both directions.\n",
    "\n",
    "    :param vertex: Any node of the global scope graph.\n",
    "    :return: The list of neighbours of the graph.\n",
    "    \"\"\"\n",
    "    neighbours1 = graph.edges.filter(\"src = '{}'\".format(vertex)).select(\n",
    "        \"dst\").distinct()\n",
    "    neighbours2 = graph.edges.filter(\"dst = '{}'\".format(vertex)).select(\n",
    "        \"src\").distinct()\n",
    "    neighbours = neighbours1.union(neighbours2)\n",
    "    return neighbours.rdd.map(lambda row: row.dst).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08bed67e-e911-43c6-8161-8eb35a77110d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_subgraph(list_vertices):\n",
    "    \"\"\"\n",
    "    Given a set of vertices, this function calculates a subgraph from the\n",
    "    original graph.\n",
    "\n",
    "    :param list_vertices: A set of vertices for which subgraph needs to be\n",
    "    created.\n",
    "\n",
    "    :return: The subgraph\n",
    "    \"\"\"\n",
    "\n",
    "    # Find all the edges between all the nodes given in the list\n",
    "    edge_motif = graph.find(\"(a)-[e]->(b)\").filter(col(\"a.id\").isin(\n",
    "        list_vertices)).filter(col(\"b.id\").isin(list_vertices))\n",
    "    edge_select = edge_motif.select(\"e.src\", \"e.dst\")\n",
    "\n",
    "    # Create the subgraph from the new edges and return it\n",
    "    return GraphFrame(graph.vertices, edge_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a67d30-0270-4b41-9000-f44cc4bfb315",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_guidance(subgraph_degree, original_degree):\n",
    "    \"\"\"\n",
    "    Calculates the guidance of a node given it's original degree and subgraph\n",
    "    degree.\n",
    "\n",
    "    :param subgraph_degree: The degree of the node in the subgraph.\n",
    "    :param original_degree: The degree of the node in the original graph.\n",
    "\n",
    "    :return: The guidance of the node.\n",
    "    \"\"\"\n",
    "    log_original_degree = log(original_degree)\n",
    "    return subgraph_degree/log_original_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "745af810-ed6e-42d6-a133-2a1323fe72bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(subgraph_degrees):\n",
    "    \"\"\"\n",
    "    Given a list of subgraph degrees, this function calls the guidance\n",
    "    function and calculates the similarity of a particular node with all it's\n",
    "    non-connected nodes.\n",
    "\n",
    "    :param subgraph_degrees: A list of lists containing the non connected node\n",
    "    and degrees of common neighbours from the subgraph.\n",
    "\n",
    "    :return: A dictionary of similarity of each non-connected node\n",
    "    \"\"\"\n",
    "    similarity_dict = []\n",
    "    for nc_node in subgraph_degrees:\n",
    "        similarity = 0\n",
    "        for common_node in nc_node[1]:\n",
    "            # Getting the degree of the common neighbour node from the original\n",
    "            # graph\n",
    "            original_degree = graph.degrees.filter(\"id = '{}'\".format(\n",
    "                common_node.id)).select(\"degree\").collect()\n",
    "\n",
    "            # Getting the degree of the common neighbour node from the subgraph\n",
    "            sub_degree = common_node.degree\n",
    "\n",
    "            # Calling the function to calculate guidance for the common\n",
    "            # neighbour node\n",
    "            guidance = get_guidance(sub_degree, original_degree[0].degree)\n",
    "\n",
    "            # Adding the guidance to the similarity of the non-connected node\n",
    "            similarity += guidance\n",
    "\n",
    "        similarity_dict.append((nc_node[0], similarity))\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3585191d-c0fd-4cd4-b97f-937dbfe8d3f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def node_processing():\n",
    "    \"\"\"\n",
    "    Takes the graph object from global scope and processes each node to find\n",
    "    all non-connected nodes and then find the similarity using the cngf\n",
    "    algorithm.\n",
    "\n",
    "    :return: The similarity of each node with all it's non connected nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the list of all nodes of the graph\n",
    "    graph_similarity = []\n",
    "    vertices_list = [i.id for i in graph.vertices.collect()]\n",
    "\n",
    "    for root_node in vertices_list:\n",
    "        print (\"Vertex \" + str(root_node))\n",
    "\n",
    "        # Get the neighbours of the node\n",
    "        root_neighbours = set(get_neighbours(root_node))\n",
    "\n",
    "        # Get the set of non-connected nodes by removing the node and the\n",
    "        # neighbours of the node from the list of nodes.\n",
    "        not_connected_nodes = set(vertices_list).difference(\n",
    "            set(root_neighbours)).difference({root_node})\n",
    "\n",
    "        subgraph_degrees = []\n",
    "\n",
    "        for nc_node in not_connected_nodes:\n",
    "\n",
    "            # Get neighbour of the non-connected node\n",
    "            node_neighbours = set(get_neighbours(nc_node))\n",
    "\n",
    "            # Get the common neighbours by taking the intersion of neighbours\n",
    "            # of both the nodes.\n",
    "            common_neighbours = root_neighbours.intersection(node_neighbours)\n",
    "\n",
    "            if common_neighbours:\n",
    "                # Create a set of all the vertices for which the subgraph needs\n",
    "                # to be created, i.e., the common neighbours, the root node and\n",
    "                # the non-connected node.\n",
    "                subgraph_vertices = common_neighbours.union({nc_node},\n",
    "                                                            {root_node})\n",
    "\n",
    "                # Call the function to create the subgraph\n",
    "                subgraph = get_subgraph(subgraph_vertices)\n",
    "\n",
    "                # Find the degrees of the common neighbours from the subgraph\n",
    "                common_neighbours_degrees = subgraph.degrees.filter(\n",
    "                    col(\"id\").isin(common_neighbours)).collect()\n",
    "                subgraph_degrees.append((nc_node, common_neighbours_degrees))\n",
    "\n",
    "        # Call the function to calculate the similarity of each non-connected\n",
    "        # node with the current node.\n",
    "        similarity = sorted(calculate_similarity(subgraph_degrees),\n",
    "                            key=operator.itemgetter(1), reverse=True)\n",
    "        graph_similarity.append((root_node, similarity))\n",
    "        print(similarity)\n",
    "    return graph_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e2fc473-a690-4d0a-bce1-cb5e63d5034a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The following code runs the CNGF algorithm and returns the list of similarity scores for each graph pair. The DBU's used after running the algorithm for vertex 0 was 11 and I was incurring charges on AWS to tune of $6.5  . At this point I interuppted the notebook to avoid being charged more than I could afford. Thus, my solution is still incomplete. \n",
    "\n",
    "The (interuppted) function spawned more than a 1500 jobs, each with only 1 stage per job(for 1 vertex). I think it can thus be inferred that my implemented solution is not parallelizable and does not effectively utilize sparks capabilites. Further analysis is needed to more effectively describe the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4db02520-a199-46e3-a2e9-c09892f9ac08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_similarity = node_processing()\n",
    "print(graph_similarity)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2023-12-16 00:02:37",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
